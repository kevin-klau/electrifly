{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a program which is in testing phase. We will use a linear regression ML model to give an SOC number for the flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the querying module\n",
    "from flight_querying import query_flights\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set up and retrieve the data from the database.\n",
    "db_connect = query_flights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data dictionary holder\n",
    "data_dict = {\n",
    "    \"Time Delta\": [],\n",
    "    \"SOC Delta\": [],\n",
    "    \"Activity\": [],\n",
    "    \"Average Power\": [],\n",
    "    \"Id\": [],\n",
    "    \"Unique Data Identifier\": []\n",
    "}\n",
    "\n",
    "# Create a increasing int variable to keep track of the Unique Data Identifier\n",
    "unique_identifier = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parser(parsing_dataframe):\n",
    "\n",
    "    global unique_identifier\n",
    "\n",
    "    # Get the current exercise\n",
    "    current_exercise = parsing_dataframe.iloc[0, parsing_dataframe.columns.get_loc('activity')]\n",
    "    id = parsing_dataframe.iloc[0, parsing_dataframe.columns.get_loc('id')]\n",
    "    max_soc, min_soc = 0, 101\n",
    "    power_list = [0]\n",
    "    min_time, max_time = 100, 0\n",
    "\n",
    "    # iterate over all the rows\n",
    "    for index, row in parsing_dataframe.iterrows():\n",
    "\n",
    "        # Get the data needed from the rows. Append the power\n",
    "        new_exercise = row[\"activity\"]\n",
    "        soc = row[\"soc\"]\n",
    "        power_list.append(row[\"power\"])\n",
    "        time = row[\"time\"]\n",
    "\n",
    "        # If the exercise changes or if the rows end.\n",
    "        if current_exercise != new_exercise or index == len(parsing_dataframe) - 1:\n",
    "\n",
    "            # Set the values \n",
    "            data_dict[\"Time Delta\"].append(round(max_time - min_time, 2))\n",
    "            data_dict[\"SOC Delta\"].append(max_soc - min_soc)\n",
    "            data_dict[\"Activity\"].append(current_exercise)\n",
    "            data_dict[\"Average Power\"].append(round(sum(power_list)/len(power_list), 2))\n",
    "            data_dict[\"Id\"].append(id)\n",
    "            data_dict[\"Unique Data Identifier\"].append(unique_identifier)\n",
    "            unique_identifier = unique_identifier + 1\n",
    "\n",
    "            # Reset all the values\n",
    "            max_soc, min_soc = soc, soc\n",
    "            power_list.clear()\n",
    "            max_time, min_time = time, time\n",
    "        \n",
    "        # SOC\n",
    "        if soc >= max_soc:\n",
    "            max_soc = soc\n",
    "        if soc <= min_soc:\n",
    "            min_soc = soc\n",
    "\n",
    "        # TIME\n",
    "        if time >= max_time:\n",
    "            max_time = time\n",
    "        if time <= min_time:\n",
    "            min_time = time\n",
    "        \n",
    "        # Change current exercise\n",
    "        current_exercise = new_exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight IDs to include\n",
    "flight_ids = [4620, 4929, 4940, 5019, 5021, 5034]\n",
    "\n",
    "# Fetch data for specified flight IDs\n",
    "# Remove NA values from each dataframe in the list and put it through the data parser\n",
    "for ids in flight_ids:\n",
    "    frame = db_connect.connect_flight_for_ml_data_prescription(ids)\n",
    "    frame = frame[frame[\"activity\"] != \"NA\"].reset_index()\n",
    "    data_parser(frame)\n",
    "\n",
    "# Concatenate data frames and shuffle the data\n",
    "# all_data = pd.concat(data_frames, axis=0).sample(frac=1, random_state=42)\n",
    "all_data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(all_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length train_x = {len(train_data)} \\n Length train_y = {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot-Encoding of the Operations columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODE\n",
    "# https://stackabuse.com/one-hot-encoding-in-python-with-pandas-and-scikit-learn/\n",
    "def one_hot(df, col, pre):\n",
    "  encoded = pd.get_dummies(df[col], prefix=pre)\n",
    "  for column in encoded:\n",
    "    encoded = encoded.rename(columns={column: col + \"_\" + column})\n",
    "  encoded['Unique Data Identifier'] = df['Unique Data Identifier']\n",
    "  return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Train data\n",
    "train_encoded = one_hot(train_data, \"Activity\", 'is')\n",
    "final_train_x = pd.merge(train_data, train_encoded, on=[\"Unique Data Identifier\"])\n",
    "final_train_y = final_train_x[\"SOC Delta\"].to_numpy()\n",
    "final_train_x = final_train_x.drop(columns=[\"SOC Delta\", \"Id\", \"Unique Data Identifier\", \"Activity\"])\n",
    "\n",
    "# Encode Test data\n",
    "test_encoded = one_hot(test_data, \"Activity\", 'is')\n",
    "final_test_x = pd.merge(test_data, test_encoded, on=[\"Unique Data Identifier\"])\n",
    "final_test_y = final_test_x[\"SOC Delta\"].to_numpy()\n",
    "final_test_x = final_test_x.drop(columns=[\"SOC Delta\", \"Id\", \"Unique Data Identifier\", \"Activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length test_encoded = {len(test_encoded)} \\n Length train_encoded = {len(train_encoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length train_x = {len(final_train_x)} \\n Length train_y = {len(final_train_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length test_x = {len(final_test_x)} \\n Length test_y = {len(final_test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Model Implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
